@article{DBLP:journals/corr/BajpaiPHC17,
  author    = {Rajiv Bajpai and
               Soujanya Poria and
               Danyuan Ho and
               Erik Cambria},
  title     = {Developing a concept-level knowledge base for sentiment analysis in
               Singlish},
  journal   = {CoRR},
  volume    = {abs/1707.04408},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.04408},
  eprinttype = {arXiv},
  eprint    = {1707.04408},
  timestamp = {Mon, 08 Mar 2021 16:26:41 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/BajpaiPHC17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  language = {Singlish}
}

@inproceedings{dabre-etal-2014-anou,
    title = "Anou Tradir: Experiences In Building Statistical Machine Translation Systems For Mauritian Creole Languages {--} Creole, {E}nglish, {F}rench",
    author = "Dabre, Raj  and
      Sukhoo, Aneerav  and
      Bhattacharyya, Pushpak",
    booktitle = "Proceedings of the 11th International Conference on Natural Language Processing",
    month = dec,
    year = "2014",
    address = "Goa, India",
    publisher = "NLP Association of India",
    url = "https://aclanthology.org/W14-5113",
    pages = "82--88",
    language = {Mauritian Creole}
}


@book{rickford1987dimensions,
  title={Dimensions of a Creole continuum: History, texts \& linguistic analysis of Guyanese Creole},
  author={Rickford, John R},
  year={1987},
  publisher={Stanford University Press},
  language={Guyanese}
}


@incollection{henriderivation,
  title={Derivation and the morphological complexity of three French-based creoles},
  author={Henri, Fabiola and Stump, Gregory and Tribout, Delphine},
  booktitle={The Complexities of Morphology},
  pages={105--135},
  year={2020},
  publisher={Oxford University Press}
}


@article{DBLP:journals/corr/BajpaiPHC17,
  author    = {Rajiv Bajpai and
               Soujanya Poria and
               Danyuan Ho and
               Erik Cambria},
  title     = {Developing a concept-level knowledge base for sentiment analysis in
               Singlish},
  journal   = {CoRR},
  volume    = {abs/1707.04408},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.04408},
  eprinttype = {arXiv},
  eprint    = {1707.04408},
  timestamp = {Mon, 08 Mar 2021 16:26:41 +0100},
  biburl    = {https://dblp.org/rec/journals/corr/BajpaiPHC17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  language = {Singlish}

}


@inproceedings{wang-etal-2017-universal,
    title = "{U}niversal {D}ependencies Parsing for Colloquial Singaporean {E}nglish",
    author = "Wang, Hongmin  and
      Zhang, Yue  and
      Chan, GuangYong Leonard  and
      Yang, Jie  and
      Chieu, Hai Leong",
    booktitle = "Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)",
    month = jul,
    year = "2017",
    address = "Vancouver, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/P17-1159",
    doi = "10.18653/v1/P17-1159",
    pages = "1732--1744",
    abstract = "Singlish can be interesting to the ACL community both linguistically as a major creole based on English, and computationally for information extraction and sentiment analysis of regional social media. We investigate dependency parsing of Singlish by constructing a dependency treebank under the Universal Dependencies scheme, and then training a neural network model by integrating English syntactic knowledge into a state-of-the-art parser trained on the Singlish treebank. Results show that English knowledge can lead to 25{\%} relative error reduction, resulting in a parser of 84.47{\%} accuracies. To the best of our knowledge, we are the first to use neural stacking to improve cross-lingual dependency parsing on low-resource languages. We make both our annotation and parser available for further research.",
    language = "Singlish",
}

@OTHER{10635_137343,
	author = {T. Chen and  Kan Min-Yen},
	title = {The National University of Singapore SMS Corpus},
	year = {2015},
	abstract = {<p> This is a corpus of SMS (Short Message Service) messages collected for research at the Department of Computer Science at the National University of Singapore. This dataset consists of 67,093 SMS messages taken from the corpus on Mar 9, 2015. The messages largely originate from Singaporeans and mostly from students attending the University. These messages were collected from volunteers who were made aware that their contributions were going to be made publicly available. The data collectors opportunistically collected as much metadata about the messages and their senders as possible, so as to enable different types of analyses. </p> <p> This corpus was collected by Tao Chen and Min-Yen Kan. If you use this data, please ensure the following paper is cited. For more details, please refer to Citation field. </p> <ul> <li>Tao Chen and Min-Yen Kan (2013). Creating a Live, Public Short Message Service Corpus: The NUS SMS Corpus. Language Resources and Evaluation, 47(2)(2013), pages 299-355. URL: <a href="https://link.springer.com/article/10.1007\%2Fs10579-012-9197-9">https://link.springer.com/article/10.1007\%2Fs10579-012-9197-9</a></li> </ul>},
}


@book{slone2001one,
  title={One Thousand One Papua New Guinean Nights: Tales form 1972-1985},
  author={Slone, Thomas H},
  volume={1},
  year={2001},
  publisher={Masalai Press}
}


@article{sebba1998phonology,
  title={Phonology meets ideology: the meaning of orthographic practices in British Creole},
  author={Sebba, Mark},
  journal={Language problems and language planning},
  volume={22},
  number={1},
  pages={19--47},
  year={1998},
  publisher={John Benjamins},
  language = {British Creole}
}


@book{baker2007making,
  title={The making of Mauritian Creole Creole. Analyses diachroniques {\`a} partir des textes anciens},
  author={Baker, Philip and Sing, Guillaume Fon},
  number={9},
  year={2007},
  publisher={Battlebridge},
  language={Mauritian Creole}
}


@article{Oyewusi2021Nigerian PidginNERC,
  title={Nigerian PidginNER : Comprehensive Named Entity Recognition for 5 Nigerian Languages},
  author={Wuraola Fisayo Oyewusi and Olubayo Adekanmbi and Ife Okoh and Vitus Onuigwe and Mary Idera Salami and Opeyemi Osakuade and Sharon Ibejih and Usman Abdullahi Musa},
  journal={ArXiv},
  year={2021},
  volume={abs/2105.00810},
  language={Nigerian Pidgin}
}

@article{adelani-etal-2021-masakhaner,
    title = "{M}asakha{NER}: Named Entity Recognition for {A}frican Languages",
    author = "Adelani, David Ifeoluwa  and
      Abbott, Jade  and
      Neubig, Graham  and
      D{'}souza, Daniel  and
      Kreutzer, Julia  and
      Lignos, Constantine  and
      Palen-Michel, Chester  and
      Buzaaba, Happy  and
      Rijhwani, Shruti  and
      Ruder, Sebastian  and
      Mayhew, Stephen  and
      Azime, Israel Abebe  and
      Muhammad, Shamsuddeen H.  and
      Emezue, Chris Chinenye  and
      Nakatumba-Nabende, Joyce  and
      Ogayo, Perez  and
      Anuoluwapo, Aremu  and
      Gitau, Catherine  and
      Mbaye, Derguene  and
      Alabi, Jesujoba  and
      Yimam, Seid Muhie  and
      Gwadabe, Tajuddeen Rabiu  and
      Ezeani, Ignatius  and
      Niyongabo, Rubungo Andre  and
      Mukiibi, Jonathan  and
      Otiende, Verrah  and
      Orife, Iroro  and
      David, Davis  and
      Ngom, Samba  and
      Adewumi, Tosin  and
      Rayson, Paul  and
      Adeyemi, Mofetoluwa  and
      Muriuki, Gerald  and
      Anebi, Emmanuel  and
      Chukwuneke, Chiamaka  and
      Odu, Nkiruka  and
      Wairagala, Eric Peter  and
      Oyerinde, Samuel  and
      Siro, Clemencia  and
      Bateesa, Tobius Saul  and
      Oloyede, Temilola  and
      Wambui, Yvonne  and
      Akinode, Victor  and
      Nabagereka, Deborah  and
      Katusiime, Maurice  and
      Awokoya, Ayodele  and
      MBOUP, Mouhamadane  and
      Gebreyohannes, Dibora  and
      Tilaye, Henok  and
      Nwaike, Kelechi  and
      Wolde, Degaga  and
      Faye, Abdoulaye  and
      Sibanda, Blessing  and
      Ahia, Orevaoghene  and
      Dossou, Bonaventure F. P.  and
      Ogueji, Kelechi  and
      DIOP, Thierno Ibrahima  and
      Diallo, Abdoulaye  and
      Akinfaderin, Adewale  and
      Marengereke, Tendai  and
      Osei, Salomey",
    journal = "Transactions of the Association for Computational Linguistics",
    volume = "9",
    year = "2021",
    address = "Cambridge, MA",
    publisher = "MIT Press",
    url = "https://aclanthology.org/2021.tacl-1.66",
    doi = "10.1162/tacl_a_00416",
    pages = "1116--1131",
    abstract = "Abstract We take a step towards addressing the under- representation of the African continent in NLP research by bringing together different stakeholders to create the first large, publicly available, high-quality dataset for named entity recognition (NER) in ten African languages. We detail the characteristics of these languages to help researchers and practitioners better understand the challenges they pose for NER tasks. We analyze our datasets and conduct an extensive empirical evaluation of state- of-the-art methods across both supervised and transfer learning settings. Finally, we release the data, code, and models to inspire future research on African NLP.1",
}

@article{Ajisafe2020TowardsET,
  title={Towards End-to-End Training of Automatic Speech Recognition for Nigerian Pidgin},
  author={Daniel Ajisafe and Oluwabukola Grace Adegboro and Esther Oduntan and Tayo Oladiran Arulogun},
  journal={ArXiv},
  year={2020},
  volume={abs/2010.11123},
  language={Nigerian Pidgin}
}

@article{Oyewusi2020SemanticEO,
  title={Semantic Enrichment of Nigerian Pidgin English for Contextual Sentiment Classification},
  author={Wuraola Fisayo Oyewusi and Olubayo Adekanmbi and Olalekan Akinsande},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.12450},
  language={Nigerian Pidgin}
}


@inproceedings{Munro10crowdsourcedtranslation,
    author = {Robert Munro},
    title = {Crowdsourced translation for emergency response in haiti: the global collaboration of local knowledge},
    booktitle = {In Relief 2.0 in Haiti},
    year = {2010},
    language={Haitian Kreyol}
}

@inproceedings{Bigi2017DevelopingRF,
  title={Developing Resources for Automated Speech Processing of the African Language Nigerian Pidgin (Nigerian Pidgin)},
  author={B. Bigi and B. Caron and Oyelere S. Abiola},
  year={2017},
  language={Nigerian Pidgin}
}

@article{Ogueji2019PidginUNMTUN,
  title={PidginUNMT: Unsupervised Neural Machine Translation from West African Pidgin to English},
  author={Kelechi Ogueji and Orevaoghene Ahia},
  journal={ArXiv},
  year={2019},
  volume={abs/1912.03444},
  language={West African Pidgin}
}

@article{Ahia2020TowardsSA,
  title={Towards Supervised and Unsupervised Neural Machine Translation Baselines for Nigerian Pidgin},
  author={Orevaoghene Ahia and Kelechi Ogueji},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.12660},
  language={Nigerian Pidgin}
}

@inproceedings{obighosh2019naija,
  title={Wétin dey with these comments? Modeling Sociolinguistic Factors Affecting Code-switching Behavior, in Nigerian Online Discussions},
  author={Ndubuisi-Obi, Innocent and Ghosh, Sayan and Jurgens, David},
  booktitle={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)},
  year={2019},
  language={Nigerian Pidgin}
}

@inproceedings{caron-etal-2019-surface,
    title = "A Surface-Syntactic {UD} Treebank for {N}aija",
    author = "Caron, Bernard  and
      Courtin, Marine  and
      Gerdes, Kim  and
      Kahane, Sylvain",
    booktitle = "Proceedings of the 18th International Workshop on Treebanks and Linguistic Theories (TLT, SyntaxFest 2019)",
    month = aug,
    year = "2019",
    address = "Paris, France",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/W19-7803",
    doi = "10.18653/v1/W19-7803",
    pages = "13--24",
    language={Nigerian Pidgin}
}

@article{Oyewusi2020SemanticEO,
  title={Semantic Enrichment of Nigerian Pidgin English for Contextual Sentiment Classification},
  author={Wuraola Fisayo Oyewusi and Olubayo Adekanmbi and O. Akinsande},
  journal={ArXiv},
  year={2020},
  volume={abs/2003.12450},
  language={Nigerian Pidgin}
}

@inproceedings{hu-etal-2011-value,
    title = "The Value of Monolingual Crowdsourcing in a Real-World Translation Scenario: Simulation using {H}aitian {C}reole Emergency {SMS} Messages",
    author = "Hu, Chang  and
      Resnik, Philip  and
      Kronrod, Yakov  and
      Eidelman, Vladimir  and
      Buzek, Olivia  and
      Bederson, Benjamin B.",
    booktitle = "Proceedings of the Sixth Workshop on Statistical Machine Translation",
    month = jul,
    year = "2011",
    address = "Edinburgh, Scotland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W11-2148",
    pages = "399--404",
    language= "Haitian Kreyol",
}

@inproceedings{hagemeijer-etal-2014-gulf,
    title = "The {G}ulf of {G}uinea Creole Corpora",
    author = "Hagemeijer, Tjerk  and
      G{\'e}n{\'e}reux, Michel  and
      Hendrickx, Iris  and
      Mendes, Am{\'a}lia  and
      Tiny, Abigail  and
      Zamora, Armando",
    booktitle = "Proceedings of the Ninth International Conference on Language Resources and Evaluation ({LREC}'14)",
    month = may,
    year = "2014",
    address = "Reykjavik, Iceland",
    publisher = "European Language Resources Association (ELRA)",
    url = "http://www.lrec-conf.org/proceedings/lrec2014/pdf/438_Paper.pdf",
    pages = "523--529",
    abstract = "We present the process of building linguistic corpora of the Portuguese-related Gulf of Guinea creoles, a cluster of four historically related languages: Santome, Angolar, Principense and Fa dAmb{\^o}. We faced the typical difficulties of languages lacking an official status, such as lack of standard spelling, language variation, lack of basic language instruments, and small data sets, which comprise data from the late 19th century to the present. In order to tackle these problems, the compiled written and transcribed spoken data collected during field work trips were adapted to a normalized spelling that was applied to the four languages. For the corpus compilation we followed corpus linguistics standards. We recorded meta data for each file and added morphosyntactic information based on a part-of-speech tag set that was designed to deal with the specificities of these languages. The corpora of three of the four creoles are already available and searchable via an online web interface.",
    language = "Guinea Creole",
}

@inproceedings{armstrong-etal-2022-jampatoisnli,
    title = "{J}am{P}atois{NLI}: A {J}amaican {P}atois Natural Language Inference Dataset",
    author = "Armstrong, Ruth-Ann  and
      Hewitt, John  and
      Manning, Christopher",
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2022",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-emnlp.389",
    pages = "5307--5320",
    language = "Jamaican Creole English",
}

@inproceedings{dabre-sukhoo-2022-kreolmorisienmt,
    title = "{K}reol{M}orisien{MT}: A Dataset for Mauritian Creole Machine Translation",
    author = "Dabre, Raj  and
      Sukhoo, Aneerav",
    editor = "He, Yulan  and
      Ji, Heng  and
      Li, Sujian  and
      Liu, Yang  and
      Chang, Chua-Hui",
    booktitle = "Findings of the Association for Computational Linguistics: AACL-IJCNLP 2022",
    month = nov,
    year = "2022",
    address = "Online only",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-aacl.3",
    pages = "22--29",
    abstract = "In this paper, we describe KreolMorisienMT, a dataset for benchmarking machine translation quality of Mauritian Creole. Mauritian Creole (Kreol Morisien) is a French-based creole and a lingua franca of the Republic of Mauritius. KreolMorisienMT consists of a parallel corpus between English and Kreol Morisien, French and Kreol Morisien and a monolingual corpus for Kreol Morisien. We first give an overview of Kreol Morisien and then describe the steps taken to create the corpora. Thereafter, we benchmark Kreol Morisien ↔ English and Kreol Morisien ↔ French models leveraging pre-trained models and multilingual transfer learning. Human evaluation reveals our systems{'} high translation quality.",
    language = "Mauritian Creole"
}

@inproceedings{macaire-etal-2022-automatic,
    title = "Automatic Speech Recognition and Query By Example for Creole Languages Documentation",
    author = "Macaire, C{\'e}cile  and
      Schwab, Didier  and
      Lecouteux, Benjamin  and
      Schang, Emmanuel",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.197",
    doi = "10.18653/v1/2022.findings-acl.197",
    pages = "2512--2520",
    abstract = "We investigate the exploitation of self-supervised models for two Creole languages with few resources: Gwadloup{\'e}yen and Morisien. Automatic language processing tools are almost non-existent for these two languages. We propose to use about one hour of annotated data to design an automatic speech recognition system for each language. We evaluate how much data is needed to obtain a query-by-example system that is usable by linguists. Moreover, our experiments show that multilingual self-supervised models are not necessarily the most efficient for Creole languages.",
    language = "Mauritian Creole"
}

@inproceedings{macaire-etal-2022-automatic,
    title = "Automatic Speech Recognition and Query By Example for Creole Languages Documentation",
    author = "Macaire, C{\'e}cile  and
      Schwab, Didier  and
      Lecouteux, Benjamin  and
      Schang, Emmanuel",
    editor = "Muresan, Smaranda  and
      Nakov, Preslav  and
      Villavicencio, Aline",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2022",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.findings-acl.197",
    doi = "10.18653/v1/2022.findings-acl.197",
    pages = "2512--2520",
    abstract = "We investigate the exploitation of self-supervised models for two Creole languages with few resources: Gwadloup{\'e}yen and Morisien. Automatic language processing tools are almost non-existent for these two languages. We propose to use about one hour of annotated data to design an automatic speech recognition system for each language. We evaluate how much data is needed to obtain a query-by-example system that is usable by linguists. Moreover, our experiments show that multilingual self-supervised models are not necessarily the most efficient for Creole languages.",
    language = "Guadeloupean Creole"
}

@inproceedings{mompelat-etal-2022-parse,
    title = "How to Parse a Creole: When Martinican Creole Meets {F}rench",
    author = {Mompelat, Ludovic  and
      Dakota, Daniel  and
      K{\"u}bler, Sandra},
    editor = "Calzolari, Nicoletta  and
      Huang, Chu-Ren  and
      Kim, Hansaem  and
      Pustejovsky, James  and
      Wanner, Leo  and
      Choi, Key-Sun  and
      Ryu, Pum-Mo  and
      Chen, Hsin-Hsi  and
      Donatelli, Lucia  and
      Ji, Heng  and
      Kurohashi, Sadao  and
      Paggio, Patrizia  and
      Xue, Nianwen  and
      Kim, Seokhwan  and
      Hahm, Younggyun  and
      He, Zhong  and
      Lee, Tony Kyungil  and
      Santus, Enrico  and
      Bond, Francis  and
      Na, Seung-Hoon",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.387",
    pages = "4397--4406",
    abstract = "We investigate methods to develop a parser for Martinican Creole, a highly under-resourced language, using a French treebank. We compare transfer learning and multi-task learning models and examine different input features and strategies to handle the massive size imbalance between the treebanks. Surprisingly, we find that a simple concatenated (French + Martinican Creole) baseline yields optimal results even though it has access to only 80 Martinican Creole sentences. POS embeddings work better than lexical ones, but they suffer from negative transfer.",
    language = "Antillean Creole"
}

@inproceedings{liu-etal-2022-singlish,
    title = "{S}inglish Message Paraphrasing: A Joint Task of Creole Translation and Text Normalization",
    author = "Liu, Zhengyuan  and
      Ni, Shikang  and
      Aw, Ai Ti  and
      Chen, Nancy F.",
    editor = "Calzolari, Nicoletta  and
      Huang, Chu-Ren  and
      Kim, Hansaem  and
      Pustejovsky, James  and
      Wanner, Leo  and
      Choi, Key-Sun  and
      Ryu, Pum-Mo  and
      Chen, Hsin-Hsi  and
      Donatelli, Lucia  and
      Ji, Heng  and
      Kurohashi, Sadao  and
      Paggio, Patrizia  and
      Xue, Nianwen  and
      Kim, Seokhwan  and
      Hahm, Younggyun  and
      He, Zhong  and
      Lee, Tony Kyungil  and
      Santus, Enrico  and
      Bond, Francis  and
      Na, Seung-Hoon",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.345",
    pages = "3924--3936",
    abstract = "Within the natural language processing community, English is by far the most resource-rich language. There is emerging interest in conducting translation via computational approaches to conform its dialects or creole languages back to standard English. This computational approach paves the way to leverage generic English language backbones, which are beneficial for various downstream tasks. However, in practical online communication scenarios, the use of language varieties is often accompanied by noisy user-generated content, making this translation task more challenging. In this work, we introduce a joint paraphrasing task of creole translation and text normalization of Singlish messages, which can shed light on how to process other language varieties and dialects. We formulate the task in three different linguistic dimensions: lexical level normalization, syntactic level editing, and semantic level rewriting. We build an annotated dataset of Singlish-to-Standard English messages, and report performance on a perturbation-resilient sequence-to-sequence model. Experimental results show that the model produces reasonable generation results, and can improve the performance of downstream tasks like stance detection.",
    language = "Singlish"
}

@inproceedings{alabi-etal-2022-adapting,
    title = "Adapting Pre-trained Language Models to {A}frican Languages via Multilingual Adaptive Fine-Tuning",
    author = "Alabi, Jesujoba O.  and
      Adelani, David Ifeoluwa  and
      Mosbach, Marius  and
      Klakow, Dietrich",
    editor = "Calzolari, Nicoletta  and
      Huang, Chu-Ren  and
      Kim, Hansaem  and
      Pustejovsky, James  and
      Wanner, Leo  and
      Choi, Key-Sun  and
      Ryu, Pum-Mo  and
      Chen, Hsin-Hsi  and
      Donatelli, Lucia  and
      Ji, Heng  and
      Kurohashi, Sadao  and
      Paggio, Patrizia  and
      Xue, Nianwen  and
      Kim, Seokhwan  and
      Hahm, Younggyun  and
      He, Zhong  and
      Lee, Tony Kyungil  and
      Santus, Enrico  and
      Bond, Francis  and
      Na, Seung-Hoon",
    booktitle = "Proceedings of the 29th International Conference on Computational Linguistics",
    month = oct,
    year = "2022",
    address = "Gyeongju, Republic of Korea",
    publisher = "International Committee on Computational Linguistics",
    url = "https://aclanthology.org/2022.coling-1.382",
    pages = "4336--4349",
    abstract = "Multilingual pre-trained language models (PLMs) have demonstrated impressive performance on several downstream tasks for both high-resourced and low-resourced languages. However, there is still a large performance drop for languages unseen during pre-training, especially African languages. One of the most effective approaches to adapt to a new language is language adaptive fine-tuning (LAFT) {---} fine-tuning a multilingual PLM on monolingual texts of a language using the pre-training objective. However, adapting to target language individually takes large disk space and limits the cross-lingual transfer abilities of the resulting models because they have been specialized for a single language. In this paper, we perform multilingual adaptive fine-tuning on 17 most-resourced African languages and three other high-resource languages widely spoken on the African continent to encourage cross-lingual transfer learning. To further specialize the multilingual PLM, we removed vocabulary tokens from the embedding layer that corresponds to non-African writing scripts before MAFT, thus reducing the model size by around 50{\%}. Our evaluation on two multilingual PLMs (AfriBERTa and XLM-R) and three NLP tasks (NER, news topic classification, and sentiment classification) shows that our approach is competitive to applying LAFT on individual languages while requiring significantly less disk space. Additionally, we show that our adapted PLM also improves the zero-shot cross-lingual transfer abilities of parameter efficient fine-tuning methods.",
    language = "Nigerian Pidgin"
}

@article{armstrong2022jampatoisnli,
  title={Jampatoisnli: A jamaican patois natural language inference dataset},
  author={Armstrong, Ruth-Ann and Hewitt, John and Manning, Christopher},
  journal={arXiv preprint arXiv:2212.03419},
  year={2022},
  language={Jamaican Patois}
}

@inproceedings{adebara-etal-2022-afrolid,
    title = "{A}fro{LID}: A Neural Language Identification Tool for {A}frican Languages",
    author = "Adebara, Ife  and
      Elmadany, AbdelRahim  and
      Abdul-Mageed, Muhammad  and
      Inciarte, Alcides",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.128",
    doi = "10.18653/v1/2022.emnlp-main.128",
    pages = "1958--1981",
    abstract = "Language identification (LID) is a crucial precursor for NLP, especially for mining web data. Problematically, most of the world{'}s 7000+ languages today are not covered by LID technologies. We address this pressing issue for Africa by introducing AfroLID, a neural LID toolkit for 517 African languages and varieties. AfroLID exploits a multi-domain web dataset manually curated from across 14 language families utilizing five orthographic systems. When evaluated on our blind Test set, AfroLID achieves 95.89 F{\_}1-score. We also compare AfroLID to five existing LID tools that each cover a small number of African languages, finding it to outperform them on most languages. We further show the utility of AfroLID in the wild by testing it on the acutely under-served Twitter domain. Finally, we offer a number of controlled case studies and perform a linguistically-motivated error analysis that allow us to both showcase AfroLID{'}s powerful capabilities and limitations",
    language = "Krio"
}

@inproceedings{adebara-etal-2022-afrolid,
    title = "{A}fro{LID}: A Neural Language Identification Tool for {A}frican Languages",
    author = "Adebara, Ife  and
      Elmadany, AbdelRahim  and
      Abdul-Mageed, Muhammad  and
      Inciarte, Alcides",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.128",
    doi = "10.18653/v1/2022.emnlp-main.128",
    pages = "1958--1981",
    abstract = "Language identification (LID) is a crucial precursor for NLP, especially for mining web data. Problematically, most of the world{'}s 7000+ languages today are not covered by LID technologies. We address this pressing issue for Africa by introducing AfroLID, a neural LID toolkit for 517 African languages and varieties. AfroLID exploits a multi-domain web dataset manually curated from across 14 language families utilizing five orthographic systems. When evaluated on our blind Test set, AfroLID achieves 95.89 F{\_}1-score. We also compare AfroLID to five existing LID tools that each cover a small number of African languages, finding it to outperform them on most languages. We further show the utility of AfroLID in the wild by testing it on the acutely under-served Twitter domain. Finally, we offer a number of controlled case studies and perform a linguistically-motivated error analysis that allow us to both showcase AfroLID{'}s powerful capabilities and limitations",
    language = "Nigerian Pidgin"
}

@inproceedings{adebara-etal-2022-afrolid,
    title = "{A}fro{LID}: A Neural Language Identification Tool for {A}frican Languages",
    author = "Adebara, Ife  and
      Elmadany, AbdelRahim  and
      Abdul-Mageed, Muhammad  and
      Inciarte, Alcides",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.128",
    doi = "10.18653/v1/2022.emnlp-main.128",
    pages = "1958--1981",
    abstract = "Language identification (LID) is a crucial precursor for NLP, especially for mining web data. Problematically, most of the world{'}s 7000+ languages today are not covered by LID technologies. We address this pressing issue for Africa by introducing AfroLID, a neural LID toolkit for 517 African languages and varieties. AfroLID exploits a multi-domain web dataset manually curated from across 14 language families utilizing five orthographic systems. When evaluated on our blind Test set, AfroLID achieves 95.89 F{\_}1-score. We also compare AfroLID to five existing LID tools that each cover a small number of African languages, finding it to outperform them on most languages. We further show the utility of AfroLID in the wild by testing it on the acutely under-served Twitter domain. Finally, we offer a number of controlled case studies and perform a linguistically-motivated error analysis that allow us to both showcase AfroLID{'}s powerful capabilities and limitations",
    language = "Cameroonian Pidgin"
}

@inproceedings{adebara-etal-2022-afrolid,
    title = "{A}fro{LID}: A Neural Language Identification Tool for {A}frican Languages",
    author = "Adebara, Ife  and
      Elmadany, AbdelRahim  and
      Abdul-Mageed, Muhammad  and
      Inciarte, Alcides",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.128",
    doi = "10.18653/v1/2022.emnlp-main.128",
    pages = "1958--1981",
    abstract = "Language identification (LID) is a crucial precursor for NLP, especially for mining web data. Problematically, most of the world{'}s 7000+ languages today are not covered by LID technologies. We address this pressing issue for Africa by introducing AfroLID, a neural LID toolkit for 517 African languages and varieties. AfroLID exploits a multi-domain web dataset manually curated from across 14 language families utilizing five orthographic systems. When evaluated on our blind Test set, AfroLID achieves 95.89 F{\_}1-score. We also compare AfroLID to five existing LID tools that each cover a small number of African languages, finding it to outperform them on most languages. We further show the utility of AfroLID in the wild by testing it on the acutely under-served Twitter domain. Finally, we offer a number of controlled case studies and perform a linguistically-motivated error analysis that allow us to both showcase AfroLID{'}s powerful capabilities and limitations",
    language = "Seychelles Creole"
}

@inproceedings{adebara-etal-2022-afrolid,
    title = "{A}fro{LID}: A Neural Language Identification Tool for {A}frican Languages",
    author = "Adebara, Ife  and
      Elmadany, AbdelRahim  and
      Abdul-Mageed, Muhammad  and
      Inciarte, Alcides",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.128",
    doi = "10.18653/v1/2022.emnlp-main.128",
    pages = "1958--1981",
    abstract = "Language identification (LID) is a crucial precursor for NLP, especially for mining web data. Problematically, most of the world{'}s 7000+ languages today are not covered by LID technologies. We address this pressing issue for Africa by introducing AfroLID, a neural LID toolkit for 517 African languages and varieties. AfroLID exploits a multi-domain web dataset manually curated from across 14 language families utilizing five orthographic systems. When evaluated on our blind Test set, AfroLID achieves 95.89 F{\_}1-score. We also compare AfroLID to five existing LID tools that each cover a small number of African languages, finding it to outperform them on most languages. We further show the utility of AfroLID in the wild by testing it on the acutely under-served Twitter domain. Finally, we offer a number of controlled case studies and perform a linguistically-motivated error analysis that allow us to both showcase AfroLID{'}s powerful capabilities and limitations",
    language = "Mauritian Creole"
}

@inproceedings{adebara-etal-2022-afrolid,
    title = "{A}fro{LID}: A Neural Language Identification Tool for {A}frican Languages",
    author = "Adebara, Ife  and
      Elmadany, AbdelRahim  and
      Abdul-Mageed, Muhammad  and
      Inciarte, Alcides",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.128",
    doi = "10.18653/v1/2022.emnlp-main.128",
    pages = "1958--1981",
    abstract = "Language identification (LID) is a crucial precursor for NLP, especially for mining web data. Problematically, most of the world{'}s 7000+ languages today are not covered by LID technologies. We address this pressing issue for Africa by introducing AfroLID, a neural LID toolkit for 517 African languages and varieties. AfroLID exploits a multi-domain web dataset manually curated from across 14 language families utilizing five orthographic systems. When evaluated on our blind Test set, AfroLID achieves 95.89 F{\_}1-score. We also compare AfroLID to five existing LID tools that each cover a small number of African languages, finding it to outperform them on most languages. We further show the utility of AfroLID in the wild by testing it on the acutely under-served Twitter domain. Finally, we offer a number of controlled case studies and perform a linguistically-motivated error analysis that allow us to both showcase AfroLID{'}s powerful capabilities and limitations",
    language = "Kituba"
}

@inproceedings{adebara-etal-2022-afrolid,
    title = "{A}fro{LID}: A Neural Language Identification Tool for {A}frican Languages",
    author = "Adebara, Ife  and
      Elmadany, AbdelRahim  and
      Abdul-Mageed, Muhammad  and
      Inciarte, Alcides",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.128",
    doi = "10.18653/v1/2022.emnlp-main.128",
    pages = "1958--1981",
    abstract = "Language identification (LID) is a crucial precursor for NLP, especially for mining web data. Problematically, most of the world{'}s 7000+ languages today are not covered by LID technologies. We address this pressing issue for Africa by introducing AfroLID, a neural LID toolkit for 517 African languages and varieties. AfroLID exploits a multi-domain web dataset manually curated from across 14 language families utilizing five orthographic systems. When evaluated on our blind Test set, AfroLID achieves 95.89 F{\_}1-score. We also compare AfroLID to five existing LID tools that each cover a small number of African languages, finding it to outperform them on most languages. We further show the utility of AfroLID in the wild by testing it on the acutely under-served Twitter domain. Finally, we offer a number of controlled case studies and perform a linguistically-motivated error analysis that allow us to both showcase AfroLID{'}s powerful capabilities and limitations",
    language = "Sango"
}

@inproceedings{adebara-etal-2022-afrolid,
    title = "{A}fro{LID}: A Neural Language Identification Tool for {A}frican Languages",
    author = "Adebara, Ife  and
      Elmadany, AbdelRahim  and
      Abdul-Mageed, Muhammad  and
      Inciarte, Alcides",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.128",
    doi = "10.18653/v1/2022.emnlp-main.128",
    pages = "1958--1981",
    abstract = "Language identification (LID) is a crucial precursor for NLP, especially for mining web data. Problematically, most of the world{'}s 7000+ languages today are not covered by LID technologies. We address this pressing issue for Africa by introducing AfroLID, a neural LID toolkit for 517 African languages and varieties. AfroLID exploits a multi-domain web dataset manually curated from across 14 language families utilizing five orthographic systems. When evaluated on our blind Test set, AfroLID achieves 95.89 F{\_}1-score. We also compare AfroLID to five existing LID tools that each cover a small number of African languages, finding it to outperform them on most languages. We further show the utility of AfroLID in the wild by testing it on the acutely under-served Twitter domain. Finally, we offer a number of controlled case studies and perform a linguistically-motivated error analysis that allow us to both showcase AfroLID{'}s powerful capabilities and limitations",
    language = "Kabuverdianu"
}

@inproceedings{adebara-etal-2022-afrolid,
    title = "{A}fro{LID}: A Neural Language Identification Tool for {A}frican Languages",
    author = "Adebara, Ife  and
      Elmadany, AbdelRahim  and
      Abdul-Mageed, Muhammad  and
      Inciarte, Alcides",
    editor = "Goldberg, Yoav  and
      Kozareva, Zornitsa  and
      Zhang, Yue",
    booktitle = "Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.emnlp-main.128",
    doi = "10.18653/v1/2022.emnlp-main.128",
    pages = "1958--1981",
    abstract = "Language identification (LID) is a crucial precursor for NLP, especially for mining web data. Problematically, most of the world{'}s 7000+ languages today are not covered by LID technologies. We address this pressing issue for Africa by introducing AfroLID, a neural LID toolkit for 517 African languages and varieties. AfroLID exploits a multi-domain web dataset manually curated from across 14 language families utilizing five orthographic systems. When evaluated on our blind Test set, AfroLID achieves 95.89 F{\_}1-score. We also compare AfroLID to five existing LID tools that each cover a small number of African languages, finding it to outperform them on most languages. We further show the utility of AfroLID in the wild by testing it on the acutely under-served Twitter domain. Finally, we offer a number of controlled case studies and perform a linguistically-motivated error analysis that allow us to both showcase AfroLID{'}s powerful capabilities and limitations",
    language = "Guinea Creole"
}

@inproceedings{chow-bond-2022-singlish,
    title = "{S}inglish Where Got Rules One? Constructing a Computational Grammar for {S}inglish",
    author = "Chow, Siew Yeng  and
      Bond, Francis",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.562",
    pages = "5243--5250",
    abstract = "Singlish is a variety of English spoken in Singapore. In this paper, we share some of its grammar features and how they are implemented in the construction of a computational grammar of Singlish as a branch of English grammar. New rules were created and existing ones from standard English grammar of the English Resource Grammar (ERG) were changed in this branch to cater to how Singlish works. In addition, Singlish lexicon was added into the grammar together with some new lexical types. We used Head-driven Phrase Structure Grammar (HPSG) as the framework for this project of a creating a working computational grammar. As part of building the language resource, we also collected and formatted some data from the internet as part of a test suite for Singlish. Finally, the computational grammar was tested against a set of gold standard trees and compared with the standard English grammar to find out how well the grammar fares in analysing Singlish.",
    language = "Singlish"
}

@inproceedings{yong-etal-2023-prompting,
    title = "Prompting Multilingual Large Language Models to Generate Code-Mixed Texts: The Case of South {E}ast {A}sian Languages",
    author = "Yong, Zheng Xin  and
      Zhang, Ruochen  and
      Forde, Jessica  and
      Wang, Skyler  and
      Subramonian, Arjun  and
      Lovenia, Holy  and
      Cahyawijaya, Samuel  and
      Winata, Genta  and
      Sutawika, Lintang  and
      Cruz, Jan Christian Blaise  and
      Tan, Yin Lin  and
      Phan, Long  and
      Phan, Long  and
      Garcia, Rowena  and
      Solorio, Thamar  and
      Aji, Alham",
    editor = "Winata, Genta  and
      Kar, Sudipta  and
      Zhukova, Marina  and
      Solorio, Thamar  and
      Diab, Mona  and
      Sitaram, Sunayana  and
      Choudhury, Monojit  and
      Bali, Kalika",
    booktitle = "Proceedings of the 6th Workshop on Computational Approaches to Linguistic Code-Switching",
    month = dec,
    year = "2023",
    address = "Singapore",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.calcs-1.5",
    doi = "10.18653/v1/2023.calcs-1.5",
    pages = "43--63",
    abstract = "While code-mixing is a common linguistic practice in many parts of the world, collecting high-quality and low-cost code-mixed data remains a challenge for natural language processing (NLP) research. The recent proliferation of Large Language Models (LLMs) compels one to ask: how capable are these systems in generating code-mixed data? In this paper, we explore prompting multilingual LLMs in a zero-shot manner to generate code-mixed data for seven languages in South East Asia (SEA), namely Indonesian, Malay, Chinese, Tagalog, Vietnamese, Tamil, and Singlish. We find that publicly available multilingual instruction-tuned models such as BLOOMZ and Flan-T5-XXL are incapable of producing texts with phrases or clauses from different languages. ChatGPT exhibits inconsistent capabilities in generating code-mixed texts, wherein its performance varies depending on the prompt template and language pairing. For instance, ChatGPT generates fluent and natural Singlish texts (an English-based creole spoken in Singapore), but for English-Tamil language pair, the system mostly produces grammatically incorrect or semantically meaningless utterances. Furthermore, it may erroneously introduce languages not specified in the prompt. Based on our investigation, existing multilingual LLMs exhibit a wide range of proficiency in code-mixed data generation for SEA languages. As such, we advise against using LLMs in this context without extensive human checks.",
    language = "Singlish"
}

@inproceedings{tatariya-etal-2023-transfer,
    title = "Transfer Learning for Code-Mixed Data: Do Pretraining Languages Matter?",
    author = "Tatariya, Kushal  and
      Lent, Heather  and
      de Lhoneux, Miryam",
    editor = "Barnes, Jeremy  and
      De Clercq, Orph{\'e}e  and
      Klinger, Roman",
    booktitle = "Proceedings of the 13th Workshop on Computational Approaches to Subjectivity, Sentiment, {\&} Social Media Analysis",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.wassa-1.32",
    doi = "10.18653/v1/2023.wassa-1.32",
    pages = "365--378",
    abstract = "Monolinguals make up a minority of the world{'}s speakers, and yet most language technologies lag behind in handling linguistic behaviours produced by bilingual and multilingual speakers. A commonly observed phenomenon in such communities is code-mixing, which is prevalent on social media, and thus requires attention in NLP research. In this work, we look into the ability of pretrained language models to handle code-mixed data, with a focus on the impact of languages present in pretraining on the downstream performance of the model as measured on the task of sentiment analysis. Ultimately, we find that the pretraining language has little effect on performance when the model sees code-mixed data during downstream finetuning. We also evaluate the models on code-mixed data in a zero-shot setting, after task-specific finetuning on a monolingual dataset. We find that this brings out differences in model performance that can be attributed to the pretraining languages. We present a thorough analysis of these findings that also looks at model performance based on the composition of participating languages in the code-mixed datasets.",
    language = "Nigerian Pidgin"
}

@article{adelani2024nigerian,
  title={Which Nigerian-Pidgin does Generative AI speak?: Issues about Representativeness and Bias for Multilingual and Low Resource Languages},
  author={Adelani, David Ifeoluwa and Do{\u{g}}ru{\"o}z, A Seza and Shode, Iyanuoluwa and Aremu, Anuoluwapo},
  journal={arXiv preprint arXiv:2404.19442},
  year={2024},
  language = "Nigerian Pidgin"
}

@inproceedings{daval-markussen-bakker-2012-explorations,
    title = "Explorations in creole research with phylogenetic tools",
    author = "Daval-Markussen, Aymeric  and
      Bakker, Peter",
    editor = "Butt, Miriam  and
      Carpendale, Sheelagh  and
      Penn, Gerald  and
      Proki{\'c}, Jelena  and
      Cysouw, Michael",
    booktitle = "Proceedings of the {EACL} 2012 Joint Workshop of {LINGVIS} {\&} {UNCLH}",
    month = apr,
    year = "2012",
    address = "Avignon, France",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/W12-0213",
    pages = "89--97",
    language = "*Various",
}

@inproceedings{murawaki-2016-statistical,
    title = "Statistical Modeling of Creole Genesis",
    author = "Murawaki, Yugo",
    editor = "Knight, Kevin  and
      Nenkova, Ani  and
      Rambow, Owen",
    booktitle = "Proceedings of the 2016 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies",
    month = jun,
    year = "2016",
    address = "San Diego, California",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/N16-1158",
    doi = "10.18653/v1/N16-1158",
    pages = "1329--1339",
    language = "*Various"
}

@inproceedings{lent-etal-2021-language,
    title = "On Language Models for Creoles",
    author = "Lent, Heather  and
      Bugliarello, Emanuele  and
      de Lhoneux, Miryam  and
      Qiu, Chen  and
      S{\o}gaard, Anders",
    editor = "Bisazza, Arianna  and
      Abend, Omri",
    booktitle = "Proceedings of the 25th Conference on Computational Natural Language Learning",
    month = nov,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.conll-1.5",
    doi = "10.18653/v1/2021.conll-1.5",
    pages = "58--71",
    abstract = "Creole languages such as Nigerian Pidgin English and Haitian Creole are under-resourced and largely ignored in the NLP literature. Creoles typically result from the fusion of a foreign language with multiple local languages, and what grammatical and lexical features are transferred to the creole is a complex process. While creoles are generally stable, the prominence of some features may be much stronger with certain demographics or in some linguistic situations. This paper makes several contributions: We collect existing corpora and release models for Haitian Creole, Nigerian Pidgin English, and Singaporean Colloquial English. We evaluate these models on intrinsic and extrinsic tasks. Motivated by the above literature, we compare standard language models with distributionally robust ones and find that, somewhat surprisingly, the standard language models are superior to the distributionally robust ones. We investigate whether this is an effect of over-parameterization or relative distributional stability, and find that the difference persists in the absence of over-parameterization, and that drift is limited, confirming the relative stability of creole languages.",
    language = "*Various"
}

@inproceedings{lent-etal-2022-ancestor,
    title = "Ancestor-to-Creole Transfer is Not a Walk in the Park",
    author = "Lent, Heather  and
      Bugliarello, Emanuele  and
      S{\o}gaard, Anders",
    editor = "Tafreshi, Shabnam  and
      Sedoc, Jo{\~a}o  and
      Rogers, Anna  and
      Drozd, Aleksandr  and
      Rumshisky, Anna  and
      Akula, Arjun",
    booktitle = "Proceedings of the Third Workshop on Insights from Negative Results in NLP",
    month = may,
    year = "2022",
    address = "Dublin, Ireland",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.insights-1.9",
    doi = "10.18653/v1/2022.insights-1.9",
    pages = "68--74",
    abstract = "We aim to learn language models for Creole languages for which large volumes of data are not readily available, and therefore explore the potential transfer from ancestor languages (the {`}Ancestry Transfer Hypothesis{'}). We find that standard transfer methods do not facilitate ancestry transfer. Surprisingly, different from other non-Creole languages, a very distinct two-phase pattern emerges for Creoles: As our training losses plateau, and language models begin to overfit on their source languages, perplexity on the Creoles drop. We explore if this compression phase can lead to practically useful language models (the {`}Ancestry Bottleneck Hypothesis{'}), but also falsify this. Moreover, we show that Creoles even exhibit this two-phase pattern even when training on random, unrelated languages. Thus Creoles seem to be typological outliers and we speculate whether there is a link between the two observations.",
    language = "*Various"
}

@inproceedings{lent-etal-2022-creole,
    title = "What a Creole Wants, What a Creole Needs",
    author = "Lent, Heather  and
      Ogueji, Kelechi  and
      de Lhoneux, Miryam  and
      Ahia, Orevaoghene  and
      S{\o}gaard, Anders",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Thirteenth Language Resources and Evaluation Conference",
    month = jun,
    year = "2022",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2022.lrec-1.691",
    pages = "6439--6449",
    abstract = "In recent years, the natural language processing (NLP) community has given increased attention to the disparity of efforts directed towards high-resource languages over low-resource ones. Efforts to remedy this delta often begin with translations of existing English datasets into other languages. However, this approach ignores that different language communities have different needs. We consider a group of low-resource languages, creole languages. Creoles are both largely absent from the NLP literature, and also often ignored by society at large due to stigma, despite these languages having sizable and vibrant communities. We demonstrate, through conversations with creole experts and surveys of creole-speaking communities, how the things needed from language technology can change dramatically from one language to another, even when the languages are considered to be very similar to each other, as with creoles. We discuss the prominent themes arising from these conversations, and ultimately demonstrate that useful language technology cannot be built without involving the relevant community.",
    language = "*Various"
}





